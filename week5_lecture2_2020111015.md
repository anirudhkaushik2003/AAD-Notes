# Week 5, Lecture 2
## Dynamic Programming
  - Dynamic programming can be used for solving problems which only have the optimal substructure property
  - It provides quite a fast solution
  - It is used when the subproblems form a Directed Acyclic Graph, a recurses to b recurses to c and so on, if this forms a cycle then we'd stay stuck in that cycle
  - When the problem has the greedy choice property as well, then we can use greedy choice property

### Shortest Path in a Directed Acyclic Graph
  - Input: A DAG G, A source S and a destination D
  - Output: We have to find the shortest path from S to D<br>
  ![image](https://user-images.githubusercontent.com/71220864/133931464-21c0bd37-eb54-4c66-8a9b-e5c11a1aeab9.png)<br><br>
  - In the above case, the destination node is E
  #### Topological Sort
  - The above graph can be reduced to the simpler form by topologically sorting it as follows (note this sorting is not unique):<br>
  ![image](https://user-images.githubusercontent.com/71220864/133931495-bc434320-cc93-4f0c-893e-895a4946b6ec.png)<br><br>
  - This gives us the order in which we have to traverse the graph in order to reach the destination node E
  #### Algorithm
  ```javascript
  initialize all dist(.) values to infinity
  dist(s) - initialize dist from s to s to 0
  for each v in V (vertext set), in linearized order:
    dist(v) = min_{(u,v) in E} (dist(u) + l(u,v)) -- gives the shortest distance from s to a node v
  ```
  - Here greedy choice property doesn't hold
  - We have to find the minimum distance over all possible distance and once we have ascertained this answer we store it
  - This reduce the computations for overlapping problems which is the essence of dynamic programming
  - For every node v we compute the shortest path by finding all edges u,v and retracing back by finding the shortest distance to you and so on till we reach node s, we choose the shortest amongst all of these and for each node we find while recursing, we store the answer
  
  
### Longest Path in General graph
  - This problem is np complete
  - The longest path has to be the hamiltonian path as it visits every vertex atleast once
  - As Hamiltonian graph is np complete the above problem is also np complete
  - If the graph has cycles then we can't use the above dp method
  - This is because to find the shortest distance to v we need to find the shortest distance to u and to find the shortest distance to v we need to find the shortest distance to u, hence we get trapped in a deadlock
  - Finding the shortest path is a lot easier than finding the longest path for a general graph
  
### Longest increasing subsequence
  - Input: a sequence of n numbers a1,a2,a3,...,an
  - A subsequence is ai1,ai2,...,aik -- 1 <= i1 < i2 < ... < in <= n
  - We have to find the longest strictly increasing subsequence of a given sequence
  - for example we have the sequence 5,2,8,6,3,6,9,7 , here the longest increasing subsequence is 2,3,6,9
  #### Approach
  - We first create a graph of all permissible transitions
  - Establish a node i for each ai and add directed edges (i,j) whenever it is possible for ai and aj to be consecutive elements in an increasing subsequence, i.e., whenever i < j and ai < aj
  ![image](https://user-images.githubusercontent.com/71220864/134066594-15d3784c-f73c-4c7b-92c9-e420ad870c48.png)<br><br>
  - Every path in the above DAG is a valid increasing subsequence
  - The longest path in the above DAG is the longest increasing subsequence
  - However the only problem is that we don't know the source
  - Let L(j) be the length of the longest increasing subsequence ending at j
  - Thus we need to find the max L(j) for all {1 <= j <= n}<br>
  ![equation](https://latex.codecogs.com/gif.latex?%5Cbg_white%20L%28j%29%20%3D%201%20&plus;%20max%7BL%28i%29%3A%20%28i%2Cj%29%20%5Cin%20E%7D)<br>
  - The length of the longest subsequence is the height of the DAG
  - Thus we start with every vertex and find the length of the longest subsequence as the sum of 1 and the subsequence characterised by a node adjacent to j namely i such that i < j i.e. there is a directed edge from node i to j
  - We then calculate L(i) by calling the function again for a neighbouring node till we reach a node which has no edges going into it
  - We store the answer for each node that we compute so as to reduce computations
  - Hence, once we reach the leaf node, we  terminate the recursion and hence we obtain the L(j)
  - Computing the max of all L(j) for 1 <= j <= n, we obtain the longest increasing subsequence by printing each i that we visited while computing L(j)
  - This concludes the solution, the algorithm is given below
  #### The Algorithm
  ```c
  for j = 1,2,...,n:
    L(j) = 1 + max{L(i):(i,j) belong to E}
  return max_j L(j)
  ```
  
