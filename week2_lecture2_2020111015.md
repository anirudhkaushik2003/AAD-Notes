# Week 2, Lecture 2
## Summary
  - We solved recurrence relations using Master Theorem, discussed Divide and conquer technique, studied strassen's algorithm for matrix multiplication and looked at kth order statistics.
## Detailed Notes
### Master Theorem
  - If<br>
  ![equation](https://latex.codecogs.com/png.latex?%5Cbg_white%20T%28n%29%20%3D%20aT%28n/b%29%20&plus;%20O%28n%5Ed%29%5C%5C%20for%5C%20some%5C%20constants%5C%20a%20%3E%200%2C%20b%3E%200%2C%20d%5Cgeq%201)<br>
  ![equation](https://latex.codecogs.com/png.latex?%5Cbg_white%20T%28n%29%20%3D%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20O%28n%5Ed%29%5C%20if%5C%20d%20%3E%20log_ba%5C%5C%20O%28n%5Ed.log%20n%29%5C%20if%5C%20d%20%3D%20log_ba%5C%5C%20O%28n%5Elog_ba%29%5C%20if%5C%20d%20%3E%20log_ba%5C%5C%20%5Cend%7Bmatrix%7D%5Cright.)<br>
  #### Proof
   ![image](https://user-images.githubusercontent.com/71220864/131689181-b2dabd33-c137-4c77-bf14-c3c62ad9f58b.png)<br>
   - Three cases arise:
      1. a/b^d < 1 -> the ratio is less than one and hence the series is decreasing, due to this, the sum will be largely dependent on O(n^d)
      2. a/b^d = 1 -> the series will remain constant and equal to n^d, thus the sum will be n^d* logn, complexity is O(n^d* logn)
      3. a/b^d > 1 -> the series is increasing and the sum will be determined by its last term i.e <br>
      ![equation](https://latex.codecogs.com/png.latex?%5Cbg_white%20O%28n%5E%7Blog_ba%7D%29)<br>
      as<br>
      ![equation](https://latex.codecogs.com/png.latex?%5Cbg_white%20n%5Ed%28a/b%5Ed%29%5E%7Blog_bn%7D%20%3D%20n%5Ed%28a%5E%7Blog_bn%7D/%28b%5E%7Blog_bn%7D%29%5Ed%29%20%3D%20a%5E%7Blog_bn%7D%20%3D%20a%5E%7B%28log_an%29*%28log_ba%29%7D%20%3D%20n%5E%7Blog_ba%7D)<br>
     
### Merge sort
  - We repeatedly split an array into half recursively, sort the elements and then merge the arrays
  - This leads to sorting an array in O(nlogn) complexity
  - This is a divide and conquer approach
  - The cost of merging at each level depends upon the size of the array which is halved at each succesive level
  - The merge operation is linear in n
  - The recurrence relation is given by:<br>
  ![equation](https://latex.codecogs.com/png.latex?%5Cbg_white%20T%28n%29%20%3D%202T%28n/2%29%20&plus;%20O%28n%29)<br>
  using master theorem the time complexity comes out to be O(nlogn), code in c is given below
```c
/* C program for Merge Sort */
#include <stdio.h>
#include <stdlib.h>

// Merges two subarrays of arr[].
// First subarray is arr[l..m]
// Second subarray is arr[m+1..r]
void merge(int arr[], int l, int m, int r)
{
	int i, j, k;
	int n1 = m - l + 1;
	int n2 = r - m;

	/* create temp arrays */
	int L[n1], R[n2];

	/* Copy data to temp arrays L[] and R[] */
	for (i = 0; i < n1; i++)
		L[i] = arr[l + i];
	for (j = 0; j < n2; j++)
		R[j] = arr[m + 1 + j];

	/* Merge the temp arrays back into arr[l..r]*/
	i = 0; // Initial index of first subarray
	j = 0; // Initial index of second subarray
	k = l; // Initial index of merged subarray
	while (i < n1 && j < n2) {
		if (L[i] <= R[j]) {
			arr[k] = L[i];
			i++;
		}
		else {
			arr[k] = R[j];
			j++;
		}
		k++;
	}

	/* Copy the remaining elements of L[], if there
	are any */
	while (i < n1) {
		arr[k] = L[i];
		i++;
		k++;
	}

	/* Copy the remaining elements of R[], if there
	are any */
	while (j < n2) {
		arr[k] = R[j];
		j++;
		k++;
	}
}

/* l is for left index and r is right index of the
sub-array of arr to be sorted */
void mergeSort(int arr[], int l, int r)
{
	if (l < r) {
		// Same as (l+r)/2, but avoids overflow for
		// large l and h
		int m = l + (r - l) / 2;

		// Sort first and second halves
		mergeSort(arr, l, m);
		mergeSort(arr, m + 1, r);

		merge(arr, l, m, r);
	}
}

/* UTILITY FUNCTIONS */
/* Function to print an array */
void printArray(int A[], int size)
{
	int i;
	for (i = 0; i < size; i++)
		printf("%d ", A[i]);
	printf("\n");
}

/* Driver code */
int main()
{
	int arr[] = { 12, 11, 13, 5, 6, 7 };
	int arr_size = sizeof(arr) / sizeof(arr[0]);

	printf("Given array is \n");
	printArray(arr, arr_size);

	mergeSort(arr, 0, arr_size - 1);

	printf("\nSorted array is \n");
	printArray(arr, arr_size);
	return 0;
}

```
  - The iterative pseudo-code (for personal reference) is given below:<br>
  ![image](https://user-images.githubusercontent.com/71220864/131693466-b4291c85-0810-47e6-b97f-69a732b65bb2.png)<br>

### Strassens Matrix Multiplication
 - Divide and Conquer 
 - Following is simple Divide and Conquer method to multiply two square matrices. 
 1. Divide matrices A and B in 4 sub-matrices of size N/2 x N/2 as shown in the below diagram. 
 2. Calculate following values recursively. ae + bg, af + bh, ce + dg and cf + dh. 
 ![image](https://user-images.githubusercontent.com/71220864/133938596-5d95155c-9083-4dfc-9adb-57f50de69de7.png)<br><br>

 -In the above method, we do 8 multiplications for matrices of size N/2 x N/2 and 4 additions. Addition of two matrices takes O(N2) time. So the time complexity can be written as 

`T(N) = 8T(N/2) + O(N2)  

From Master's Theorem, time complexity of above method is O(N3)
which is unfortunately same as the above naive method`
   

